{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.0856306 ,  0.99734545,  0.2829785 , ...,  1.15883311,\n",
       "        2.28374562, -1.31827151])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_signal(size, outliers_size=0.01):\n",
    "    sig_normal = np.random.normal(loc=0, scale=1, size=(size, 1))\n",
    "#     print(sig_normal)\n",
    "    sig = np.expand_dims(sig_normal, axis=1)\n",
    "#     print(sig)\n",
    "    if outliers_size < 1:  # percentage.\n",
    "        outliers_size = int(size * outliers_size)\n",
    "    random_indices = np.random.choice(range(size), size=outliers_size, replace=False)\n",
    "    sig[random_indices] = np.random.randint(6, 9, 1)[0]\n",
    "    return sig, random_indices\n",
    "\n",
    "sig, random_indices = get_signal(100 * 1000, outliers_size=0)\n",
    "sig.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99991, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "def prepare_sequences(x_train, window_length, random_indices):\n",
    "    full_sequence = x_train.flatten()\n",
    "    windows = []\n",
    "    outliers = []\n",
    "    for window_start in range(0, len(full_sequence) - window_length + 1):\n",
    "        window_end = window_start + window_length\n",
    "        window_range = range(window_start, window_end)\n",
    "        window = list(full_sequence[window_range])\n",
    "        contain_outlier = len(set(window_range).intersection(set(random_indices))) > 0\n",
    "        outliers.append(contain_outlier)\n",
    "        windows.append(window)\n",
    "#     print(np.array(windows).shape)\n",
    "    return np.expand_dims(np.array(windows), axis=2), outliers\n",
    "\n",
    "x_train, _ = prepare_sequences(sig, 10, [])\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp = 0, fn = 0, fp = 2955, tn = 97036\n",
      "precision = 0.0, hit_rate = 0.0, accuracy = 0.970447340261\n"
     ]
    }
   ],
   "source": [
    "def tp_fn_fp_tn(total, expected, actual):\n",
    "    tp = len(set(expected).intersection(set(actual)))\n",
    "    fn = len(set(expected) - set(actual))\n",
    "    fp = len(set(actual) - set(expected))\n",
    "    tn = len((total - set(expected)).intersection(total - set(actual)))\n",
    "    return tp, fn, fp, tn\n",
    "\n",
    "\n",
    "def main():\n",
    "    window_length = 10\n",
    "    select_only_last_state = False\n",
    "    model_file = 'model.h5'\n",
    "    hidden_dim = 16\n",
    "\n",
    "    # no outliers.\n",
    "    signal_train, _ = get_signal(100000, outliers_size=0)\n",
    "    x_train, _ = prepare_sequences(signal_train, window_length, [])\n",
    "\n",
    "    # 1 percent are outliers.\n",
    "    signal_test, random_indices = get_signal(100000, outliers_size=0.0)\n",
    "    x_test, contain_outliers = prepare_sequences(signal_test, window_length, random_indices)\n",
    "    outlier_indices = np.where(contain_outliers)[0]\n",
    "\n",
    "    if os.path.isfile(model_file):\n",
    "        m = load_model(model_file)\n",
    "    else:\n",
    "        m = Sequential()\n",
    "        if select_only_last_state:\n",
    "            m.add(LSTM(hidden_dim, input_shape=(window_length, 1), return_sequences=False))\n",
    "            m.add(RepeatVector(window_length))\n",
    "        else:\n",
    "            m.add(LSTM(hidden_dim, input_shape=(window_length, 1), return_sequences=True))\n",
    "        m.add(Dropout(rate=0.1))\n",
    "        m.add(LSTM(1, return_sequences=True, activation='linear'))\n",
    "        m.compile(loss='mse', optimizer='adam')\n",
    "        m.fit(x_train, x_train, batch_size=64, epochs=5, validation_data=(x_test, x_test))\n",
    "        m.save(model_file)\n",
    "\n",
    "    pred_x_test = m.predict(x_test)\n",
    "    mae_of_predictions = np.squeeze(np.max(np.square(pred_x_test - x_test), axis=1))\n",
    "    mae_threshold = np.mean(mae_of_predictions) + np.std(mae_of_predictions)  # can use a running mean instead.\n",
    "    actual = np.where(mae_of_predictions > mae_threshold)[0]\n",
    "\n",
    "    tp, fn, fp, tn = tp_fn_fp_tn(set(range(len(pred_x_test))), outlier_indices, actual)\n",
    "    print(\"tp = {}, fn = {}, fp = {}, tn = {}\".format(tp, fn, fp, tn))\n",
    "    precision = float(tp) / (tp + fp)\n",
    "    if tp + fn != 0.0:\n",
    "        hit_rate = float(tp) / (tp + fn)\n",
    "    else:\n",
    "        hit_rate = float(tp) / 0.000001\n",
    "    accuracy = float(tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "    print('precision = {}, hit_rate = {}, accuracy = {}'.format(precision, hit_rate, accuracy))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
